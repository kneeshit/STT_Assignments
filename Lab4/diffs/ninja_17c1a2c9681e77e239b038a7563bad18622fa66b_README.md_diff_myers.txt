diff --git a/README.md b/README.md
index 662c6e2..8a72412 100644
--- a/README.md
+++ b/README.md
@@ -1,19 +1,19 @@
 <br>English | [简体中文](README_zh.md)
 
-[![CI](https://github.com/gngpp/opengpt/actions/workflows/CI.yml/badge.svg)](https://github.com/gngpp/opengpt/actions/workflows/CI.yml)
-[![CI](https://github.com/gngpp/opengpt/actions/workflows/Release.yml/badge.svg)](https://github.com/gngpp/opengpt/actions/workflows/Release.yml)
+[![CI](https://github.com/gngpp/ninja/actions/workflows/CI.yml/badge.svg)](https://github.com/gngpp/ninja/actions/workflows/CI.yml)
+[![CI](https://github.com/gngpp/ninja/actions/workflows/Release.yml/badge.svg)](https://github.com/gngpp/ninja/actions/workflows/Release.yml)
 	<a target="_blank" href="https://github.com/gngpp/vdns/blob/main/LICENSE">
 		<img src="https://img.shields.io/badge/license-MIT-blue.svg"/>
 	</a>
-  <a href="https://github.com/gngpp/opengpt/releases">
-    <img src="https://img.shields.io/github/release/gngpp/opengpt.svg?style=flat">
-  </a><a href="https://github.com/gngpp/opengpt/releases">
-    <img src="https://img.shields.io/github/downloads/gngpp/opengpt/total?style=flat">
+  <a href="https://github.com/gngpp/ninja/releases">
+    <img src="https://img.shields.io/github/release/gngpp/ninja.svg?style=flat">
+  </a><a href="https://github.com/gngpp/ninja/releases">
+    <img src="https://img.shields.io/github/downloads/gngpp/ninja/total?style=flat">
   </a>
-  [![](https://img.shields.io/docker/image-size/gngpp/opengpt)](https://registry.hub.docker.com/r/gngpp/opengpt)
-  [![Docker Image](https://img.shields.io/docker/pulls/gngpp/opengpt.svg)](https://hub.docker.com/r/gngpp/opengpt/)
+  [![](https://img.shields.io/docker/image-size/gngpp/ninja)](https://registry.hub.docker.com/r/gngpp/ninja)
+  [![Docker Image](https://img.shields.io/docker/pulls/gngpp/ninja.svg)](https://hub.docker.com/r/gngpp/ninja/)
 
-# opengpt
+# ninja
 
 A reverse engineered unofficial `ChatGPT` proxy (bypass Cloudflare 403 Access Denied)
 
@@ -97,35 +97,35 @@ Sending a `GPT4` conversation requires `Arkose Token` to be sent as a parameter,
 
 - #### Ubuntu(Other Linux)
 
-Making [Releases](https://github.com/gngpp/opengpt/releases/latest) has a precompiled deb package, binaries, in Ubuntu, for example:
+Making [Releases](https://github.com/gngpp/ninja/releases/latest) has a precompiled deb package, binaries, in Ubuntu, for example:
 
 ```shell
-wget https://github.com/gngpp/opengpt/releases/download/v0.5.1/opengpt-0.5.1-x86_64-unknown-linux-musl.deb
-dpkg -i opengpt-0.5.1-x86_64-unknown-linux-musl.deb
-opengpt serve run
+wget https://github.com/gngpp/ninja/releases/download/v0.5.1/ninja-0.5.1-x86_64-unknown-linux-musl.deb
+dpkg -i ninja-0.5.1-x86_64-unknown-linux-musl.deb
+ninja serve run
 ```
 
 - #### OpenWrt
 
-There are pre-compiled ipk files in GitHub [Releases](https://github.com/gngpp/opengpt/releases/latest), which currently provide versions of aarch64/x86_64 and other architectures. After downloading, use opkg to install, and use nanopi r4s as example:
+There are pre-compiled ipk files in GitHub [Releases](https://github.com/gngpp/ninja/releases/latest), which currently provide versions of aarch64/x86_64 and other architectures. After downloading, use opkg to install, and use nanopi r4s as example:
 
 ```shell
-wget https://github.com/gngpp/opengpt/releases/download/v0.5.1/opengpt_0.5.1_aarch64_generic.ipk
-wget https://github.com/gngpp/opengpt/releases/download/v0.5.1/luci-app-opengpt_1.0.6-1_all.ipk
-wget https://github.com/gngpp/opengpt/releases/download/v0.5.1/luci-i18n-opengpt-zh-cn_1.0.6-1_all.ipk
+wget https://github.com/gngpp/ninja/releases/download/v0.5.1/ninja_0.5.1_aarch64_generic.ipk
+wget https://github.com/gngpp/ninja/releases/download/v0.5.1/luci-app-ninja_1.0.6-1_all.ipk
+wget https://github.com/gngpp/ninja/releases/download/v0.5.1/luci-i18n-ninja-zh-cn_1.0.6-1_all.ipk
 
-opkg install opengpt_0.5.1_aarch64_generic.ipk
-opkg install luci-app-opengpt_1.0.6-1_all.ipk
-opkg install luci-i18n-opengpt-zh-cn_1.0.6-1_all.ipk
+opkg install ninja_0.5.1_aarch64_generic.ipk
+opkg install luci-app-ninja_1.0.6-1_all.ipk
+opkg install luci-i18n-ninja-zh-cn_1.0.6-1_all.ipk
 ```
 
 - #### Docker
 
 ```shell
-docker run --rm -it -p 7999:7999 --name=opengpt \
+docker run --rm -it -p 7999:7999 --name=ninja \
   -e WORKERS=1 \
   -e LOG=info \
-  gngpp/opengpt:latest serve run
+  gngpp/ninja:latest serve run
 ```
 
 - Docker Compose
@@ -134,9 +134,9 @@ docker run --rm -it -p 7999:7999 --name=opengpt \
 version: '3'
 
 services:
-  opengpt:
-    image: ghcr.io/gngpp/opengpt:latest
-    container_name: opengpt
+  ninja:
+    image: ghcr.io/gngpp/ninja:latest
+    container_name: ninja
     restart: unless-stopped
     environment:
       - TZ=Asia/Shanghai
@@ -173,10 +173,10 @@ services:
 ### Command Manual
 
 ```shell
-$ opengpt serve --help
+$ ninja serve --help
 Start the http server
 
-Usage: opengpt serve run [OPTIONS]
+Usage: ninja serve run [OPTIONS]
 
 Options:
   -C, --config <CONFIG>
@@ -256,7 +256,7 @@ Options:
 sudo apt update -y && sudo apt install rename
 
 # Native compilation
-git clone https://github.com/gngpp/opengpt.git && cd opengpt
+git clone https://github.com/gngpp/ninja.git && cd ninja
 ./build.sh
 
 # Cross-platform compilation, relying on docker (if you can solve cross-platform compilation dependencies on your own)
@@ -270,7 +270,7 @@ docker run --rm -it --user=$UID:$(id -g $USER) \
   -v $(pwd):/home/rust/src \
   -v $HOME/.cargo/registry:/root/.cargo/registry \
   -v $HOME/.cargo/git:/root/.cargo/git \
-  ghcr.io/gngpp/opengpt-builder:x86_64-unknown-linux-musl \
+  ghcr.io/gngpp/ninja-builder:x86_64-unknown-linux-musl \
   cargo build --release
 ```
 
@@ -278,9 +278,9 @@ docker run --rm -it --user=$UID:$(id -g $USER) \
 
 ```shell
 cd package
-svn co https://github.com/gngpp/opengpt/trunk/openwrt
+svn co https://github.com/gngpp/ninja/trunk/openwrt
 cd -
-make menuconfig # choose LUCI->Applications->luci-app-opengpt  
+make menuconfig # choose LUCI->Applications->luci-app-ninja  
 make V=s
 ```
 
